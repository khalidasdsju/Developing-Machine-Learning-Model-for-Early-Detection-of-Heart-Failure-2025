models:
  logistic_regression:
    name: Logistic Regression
    params:
      C: 0.3
      solver: 'liblinear'
      penalty: 'l1'
      class_weight: 'balanced'
      random_state: 42

  knn:
    name: K-Nearest Neighbors
    params:
      n_neighbors: 5
      weights: 'distance'
      algorithm: 'ball_tree'
      leaf_size: 20
      p: 2

  naive_bayes:
    name: Naive Bayes
    params:
      var_smoothing: 1e-8

  decision_tree:
    name: Decision Tree
    params:
      criterion: 'entropy'
      random_state: 42
  random_forest:
    name: Random Forest
    params:
      n_estimators: 300
      max_depth: 15
      min_samples_split: 3
      min_samples_leaf: 1
      class_weight: 'balanced'
      random_state: 42

  svm:
    name: Support Vector Machine
    params:
      C: 5.0
      kernel: 'rbf'
      gamma: 'scale'
      probability: True
      class_weight: 'balanced'
      random_state: 42

  ridge:
    name: Ridge Classifier
    params:
      alpha: 0.3
      class_weight: 'balanced'
      random_state: 42

  lda:
    name: Linear Discriminant Analysis
    params:
      solver: 'eigen'
      shrinkage: 'auto'

  adaboost:
    name: AdaBoost
    params:
      n_estimators: 200
      learning_rate: 0.05
      random_state: 42

  gradient_boosting:
    name: Gradient Boosting
    params:
      learning_rate: 0.03
      n_estimators: 250
      max_depth: 10
      min_samples_split: 3
      min_samples_leaf: 2
      subsample: 0.85
      random_state: 42

  extra_trees:
    name: Extra Trees Classifier
    params:
      n_estimators: 300
      max_depth: 12
      min_samples_split: 4
      random_state: 42

  lightgbm:
    name: LightGBM
    params:
      colsample_bytree: 0.9
      learning_rate: 0.03
      max_depth: 20
      min_child_samples: 5
      n_estimators: 250
      num_leaves: 90
      subsample: 0.85
      class_weight: 'balanced'
      verbose: -1
      random_state: 42

  mlp:
    name: Multi-Layer Perceptron (MLP)
    params:
      hidden_layer_sizes: [256, 128, 64]
      activation: 'relu'
      solver: 'adam'
      alpha: 0.0001
      batch_size: 16
      learning_rate: 'adaptive'
      max_iter: 500
      random_state: 42

  xgboost:
    name: XGBoost
    params:
      colsample_bytree: 0.8
      learning_rate: 0.03
      max_depth: 12
      min_child_weight: 4
      n_estimators: 250
      subsample: 0.85
      gamma: 0.1
      reg_alpha: 0.1
      reg_lambda: 0.1
      scale_pos_weight: 1
      random_state: 42

  catboost:
    name: CatBoost
    params:
      iterations: 250
      learning_rate: 0.03
      depth: 14
      min_data_in_leaf: 5
      random_seed: 42
      subsample: 0.85
      l2_leaf_reg: 3
      class_weights: [1, 4]
      verbose: 0
